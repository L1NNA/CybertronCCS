{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122676be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/cs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GemmaTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92286a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 17.56it/s]\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"google/codegemma-2b\"\n",
    "tokenizer = GemmaTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id\n",
    ").to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f471cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(labels, predictions, logits):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "    accuracy = 100 * np.sum(np.diag(cm)) / np.sum(cm)\n",
    "\n",
    "    true_positives = cm[1, 1]\n",
    "    false_positives = cm[0, 1]\n",
    "    false_negatives = cm[1, 0]\n",
    "    true_negatives = cm[0, 0]\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives + 1e-5)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-5)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-5)\n",
    "    return accuracy, precision, recall, f1, roc_auc_score(labels, logits)\n",
    "\n",
    "\n",
    "def eval(key, stage, model, tokenizer, max_length=1024):\n",
    "    file_path = f'{key}_{stage}.pickle'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        sources = pickle.load(file)\n",
    "        \n",
    "    logits = []\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for source, dest, label in tqdm(sources):\n",
    "            if len(source) > max_length:\n",
    "                source = source[:max_length]\n",
    "            if len(dest) > max_length:\n",
    "                dest = dest[:max_length]\n",
    "            inputs = tokenizer([source, dest], return_tensors=\"pt\", padding=True).to(model.device)\n",
    "            outputs = model(**inputs).logits[:, -1, :]\n",
    "            outputs /= outputs.norm(dim=1, keepdim=True)\n",
    "            logit = (outputs[0] * outputs[1]).sum().detach().item()\n",
    "            \n",
    "            predictions.append(0 if logit < 0 else 1)\n",
    "            logits.append((logit + 1) / 2)\n",
    "            labels.append(label)\n",
    "                \n",
    "        accuracy, precision, recall, f1, auroc = confusion(labels, predictions, labels)\n",
    "        print('{}_{}: accuracy, precision, recall, f1, auroc: {:.2f}, {:.2f}, {:.2f}, {:.2f}, {:.2f}'\\\n",
    "              .format(key, stage, accuracy, auroc, precision, recall, f1))\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4f514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'exp_all_m1': 'w_sco',\n",
    "    'exp_var_m1': 'w_object',\n",
    "    'exp_val_m1': 'w_string',\n",
    "    'exp_ast_m1': 'w_control',\n",
    "    'exp_all_m2': 'sco',\n",
    "    'exp_var_m2': 'object',\n",
    "    'exp_val_m2': 'string',\n",
    "    'exp_ast_m2': 'control',\n",
    "    'exp_all_m3': 'sco_dead',\n",
    "    'exp_var_m3': 'object_dead',\n",
    "    'exp_val_m3': 'string_dead',\n",
    "    'exp_ast_m3': 'control_dead',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d026c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [19:07<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_all_m1_test: accuracy, precision, recall, f1, auroc: 49.53, 1.00, 0.49, 1.00, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [13:13<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_var_m1_test: accuracy, precision, recall, f1, auroc: 49.19, 1.00, 0.49, 1.00, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [14:33<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_val_m1_test: accuracy, precision, recall, f1, auroc: 50.44, 1.00, 0.50, 1.00, 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [15:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_ast_m1_test: accuracy, precision, recall, f1, auroc: 50.28, 1.00, 0.50, 1.00, 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [26:28<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_all_m2_test: accuracy, precision, recall, f1, auroc: 49.75, 1.00, 0.50, 0.99, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [20:04<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_var_m2_test: accuracy, precision, recall, f1, auroc: 50.47, 1.00, 0.51, 1.00, 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [22:16<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_val_m2_test: accuracy, precision, recall, f1, auroc: 50.28, 1.00, 0.50, 1.00, 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [21:49<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_ast_m2_test: accuracy, precision, recall, f1, auroc: 50.03, 1.00, 0.50, 0.99, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [30:46<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_all_m3_test: accuracy, precision, recall, f1, auroc: 49.56, 1.00, 0.50, 0.99, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [25:02<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_var_m3_test: accuracy, precision, recall, f1, auroc: 50.64, 1.00, 0.51, 1.00, 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [29:04<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_val_m3_test: accuracy, precision, recall, f1, auroc: 49.78, 1.00, 0.50, 1.00, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [26:11<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_ast_m3_test: accuracy, precision, recall, f1, auroc: 49.67, 1.00, 0.50, 0.99, 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in mapping.keys():\n",
    "    eval(key, 'test', model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235aefdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
